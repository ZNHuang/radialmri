{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bsub_recon.sh\t\t       sim_BC33.txt\r\n",
      "bsub_sim.sh\t\t       sim_list.txt\r\n",
      "cg.py\t\t\t       sim_loop_20210301_spk55.sh\r\n",
      "Radial_simulation_origsmap.py  sim.sh\r\n",
      "recon_fromoriginalkspace.py    simulation_and_reconstruction_beta.py\r\n",
      "recon_loop.sh\t\t       simulation_and_reconstruction.py\r\n",
      "S0_and_smap.py\t\t       test.ipynb\r\n",
      "sim_and_recon.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python sim_and_recon.py -c $caseidx -i 0 -d . --spokes 21\n",
      "/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/dask/config.py:161: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "input noise level = None, iterations = 0\n",
      "sim_and_recon.py:89: UserWarning: Iteration <= 0, no reconstruction, only simulation\n",
      "  warnings.warn('Iteration <= 0, no reconstruction, only simulation')\n",
      "Running simulation\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'ID', 'S0', 'aif', 'cts', 'mask', 'parMap', 'simImg', 'smap_complex'])\n",
      "smap_loaded.shape torch.Size([1, 16, 2, 320, 320])\n",
      "torch.Size([22, 16, 2, 13440])\n",
      "torch.Size([22, 16, 2, 13440])\n",
      "torch.Size([22, 2, 320, 320])\n",
      "nl 1.3310973008628934e-06\n",
      "/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "!bash sim.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/dask/config.py:161: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "input noise level = None, iterations = 32\n",
      "Will run iGRASP(if lambda1 != None) reconstruction for 32 iterations with lamdba1=None\n",
      "Only reconstruction from simulation file: BC33_sim21spokes_origsmap_None_1.33e-06.mat\n",
      "torch.Size([1, 16, 2, 320, 320])\n",
      "(640,)\n",
      "smap_reest torch.Size([1, 16, 2, 320, 320])\n",
      "torch.Size([1, 16, 2, 320, 320])\n",
      "torch.Size([1, 16, 2, 320, 320])\n",
      "sim_and_recon.py:297: UserWarning: Not lambda1 is specified, calculate that as it = 2.5%max(abs(adjnufft(kspaceinoneframe)))\n",
      "  warnings.warn('Not lambda1 is specified, calculate that as it = 2.5%max(abs(adjnufft(kspaceinoneframe)))')\n",
      "torch.Size([22, 2, 320, 320])\n",
      "(22, 320, 320)\n",
      "lambda1 = 1.2434238669811748e-06\n",
      "./sim_21spokes_loadedsmap_caseBC29_csNone_Curve__lambda1.2434238669811748e-06_tolerance1e-12_iterations32_noise1.33e-06_target_loadedsmap_nodcomp.png\n",
      "iteration  0\n",
      "-> 0.0020925, 0.0020450, L-S 20\n",
      "-> 0.0020450, 0.0020259, L-S 4\n",
      "-> 0.0020259, 0.0018790, L-S 2\n",
      "-> 0.0018790, 0.0017690, L-S 2\n",
      "-> 0.0017690, 0.0016765, L-S 3\n",
      "-> 0.0016765, 0.0015915, L-S 1\n",
      "-> 0.0015915, 0.0015310, L-S 2\n",
      "-> 0.0015310, 0.0014540, L-S 1\n",
      "-> 0.0014540, 0.0014124, L-S 2\n",
      "-> 0.0014124, 0.0012879, L-S 2\n",
      "-> 0.0012879, 0.0011894, L-S 2\n",
      "loss= 0.0011894182534888387\n",
      "iteration  1\n",
      "-> 0.0011894, 0.0009676, L-S 23\n",
      "-> 0.0009676, 0.0008091, L-S 0\n",
      "-> 0.0008091, 0.0007326, L-S 0\n",
      "-> 0.0007326, 0.0006955, L-S 2\n",
      "-> 0.0006955, 0.0006872, L-S 2\n",
      "-> 0.0006872, 0.0006848, L-S 3\n",
      "-> 0.0006848, 0.0006451, L-S 2\n",
      "-> 0.0006451, 0.0006245, L-S 1\n",
      "-> 0.0006245, 0.0005828, L-S 2\n",
      "-> 0.0005828, 0.0005483, L-S 2\n",
      "-> 0.0005483, 0.0005450, L-S 1\n",
      "loss= 0.0005450253956951201\n",
      "iteration  2\n",
      "-> 0.0005450, 0.0004866, L-S 23\n",
      "-> 0.0004866, 0.0004257, L-S 0\n",
      "-> 0.0004257, 0.0003778, L-S 1\n",
      "-> 0.0003778, 0.0003426, L-S 0\n",
      "-> 0.0003426, 0.0003032, L-S 2\n",
      "-> 0.0003032, 0.0002886, L-S 1\n",
      "-> 0.0002886, 0.0002800, L-S 2\n",
      "-> 0.0002800, 0.0002727, L-S 2\n",
      "-> 0.0002727, 0.0002664, L-S 2\n",
      "-> 0.0002664, 0.0002596, L-S 1\n",
      "-> 0.0002596, 0.0002468, L-S 2\n",
      "loss= 0.0002468154125381261\n",
      "iteration  3\n",
      "-> 0.0002468, 0.0002309, L-S 23\n",
      "-> 0.0002309, 0.0002200, L-S 0\n",
      "-> 0.0002200, 0.0002112, L-S 1\n",
      "-> 0.0002112, 0.0002067, L-S 0\n",
      "-> 0.0002067, 0.0001988, L-S 1\n",
      "-> 0.0001988, 0.0001880, L-S 2\n",
      "-> 0.0001880, 0.0001841, L-S 2\n",
      "-> 0.0001841, 0.0001811, L-S 1\n",
      "-> 0.0001811, 0.0001773, L-S 1\n",
      "-> 0.0001773, 0.0001713, L-S 2\n",
      "-> 0.0001713, 0.0001667, L-S 1\n",
      "loss= 0.00016674035578034818\n",
      "iteration  4\n",
      "-> 0.0001667, 0.0001579, L-S 23\n",
      "-> 0.0001579, 0.0001495, L-S 0\n",
      "-> 0.0001495, 0.0001431, L-S 1\n",
      "-> 0.0001431, 0.0001401, L-S 1\n",
      "-> 0.0001401, 0.0001370, L-S 1\n",
      "-> 0.0001370, 0.0001346, L-S 1\n",
      "-> 0.0001346, 0.0001316, L-S 1\n",
      "-> 0.0001316, 0.0001296, L-S 1\n",
      "-> 0.0001296, 0.0001276, L-S 1\n",
      "-> 0.0001276, 0.0001252, L-S 2\n",
      "-> 0.0001252, 0.0001240, L-S 1\n",
      "loss= 0.00012396943930070847\n",
      "iteration  5\n",
      "-> 0.0001240, 0.0001231, L-S 23\n",
      "-> 0.0001231, 0.0001223, L-S 0\n",
      "-> 0.0001223, 0.0001199, L-S 1\n",
      "-> 0.0001199, 0.0001186, L-S 1\n",
      "-> 0.0001186, 0.0001180, L-S 1\n",
      "-> 0.0001180, 0.0001168, L-S 2\n",
      "-> 0.0001168, 0.0001131, L-S 2\n",
      "-> 0.0001131, 0.0001122, L-S 1\n",
      "-> 0.0001122, 0.0001114, L-S 1\n",
      "-> 0.0001114, 0.0001104, L-S 1\n",
      "-> 0.0001104, 0.0001097, L-S 1\n",
      "loss= 0.00010968864080496132\n",
      "iteration  6\n",
      "-> 0.0001097, 0.0001080, L-S 23\n",
      "-> 0.0001080, 0.0001066, L-S 0\n",
      "-> 0.0001066, 0.0001052, L-S 1\n",
      "-> 0.0001052, 0.0001046, L-S 2\n",
      "-> 0.0001046, 0.0001026, L-S 2\n",
      "-> 0.0001026, 0.0001020, L-S 1\n",
      "-> 0.0001020, 0.0001016, L-S 1\n",
      "-> 0.0001016, 0.0001006, L-S 1\n",
      "-> 0.0001006, 0.0000996, L-S 2\n",
      "-> 0.0000996, 0.0000993, L-S 1\n",
      "-> 0.0000993, 0.0000991, L-S 3\n",
      "loss= 9.908796346280724e-05\n",
      "iteration  7\n",
      "-> 0.0000991, 0.0000986, L-S 23\n",
      "-> 0.0000986, 0.0000984, L-S 0\n",
      "-> 0.0000984, 0.0000976, L-S 1\n",
      "-> 0.0000976, 0.0000971, L-S 2\n",
      "-> 0.0000971, 0.0000959, L-S 2\n",
      "-> 0.0000959, 0.0000959, L-S 1\n",
      "-> 0.0000959, 0.0000957, L-S 2\n",
      "-> 0.0000957, 0.0000956, L-S 1\n",
      "-> 0.0000956, 0.0000955, L-S 2\n",
      "-> 0.0000955, 0.0000941, L-S 2\n",
      "-> 0.0000941, 0.0000932, L-S 1\n",
      "loss= 9.318764205090702e-05\n",
      "iteration  8\n",
      "-> 0.0000932, 0.0000928, L-S 23\n",
      "-> 0.0000928, 0.0000924, L-S 0\n",
      "-> 0.0000924, 0.0000921, L-S 1\n",
      "-> 0.0000921, 0.0000919, L-S 2\n",
      "-> 0.0000919, 0.0000918, L-S 1\n",
      "-> 0.0000918, 0.0000917, L-S 3\n",
      "-> 0.0000917, 0.0000911, L-S 1\n",
      "-> 0.0000911, 0.0000911, L-S 0\n",
      "-> 0.0000911, 0.0000910, L-S 2\n",
      "-> 0.0000910, 0.0000902, L-S 2\n",
      "-> 0.0000902, 0.0000897, L-S 2\n",
      "loss= 8.96643177838996e-05\n",
      "iteration  9\n",
      "-> 0.0000897, 0.0000892, L-S 23\n",
      "-> 0.0000892, 0.0000889, L-S 0\n",
      "-> 0.0000889, 0.0000888, L-S 1\n",
      "-> 0.0000888, 0.0000887, L-S 2\n",
      "-> 0.0000887, 0.0000881, L-S 2\n",
      "-> 0.0000881, 0.0000880, L-S 1\n",
      "-> 0.0000880, 0.0000878, L-S 1\n",
      "-> 0.0000878, 0.0000875, L-S 2\n",
      "-> 0.0000875, 0.0000874, L-S 1\n",
      "-> 0.0000874, 0.0000871, L-S 1\n",
      "-> 0.0000871, 0.0000868, L-S 1\n",
      "loss= 8.682428597239777e-05\n",
      "iteration  10\n",
      "-> 0.0000868, 0.0000864, L-S 24\n",
      "-> 0.0000864, 0.0000862, L-S 0\n",
      "-> 0.0000862, 0.0000861, L-S 0\n",
      "-> 0.0000861, 0.0000861, L-S 4\n",
      "-> 0.0000861, 0.0000861, L-S 1\n",
      "-> 0.0000861, 0.0000861, L-S 2\n",
      "-> 0.0000861, 0.0000860, L-S 1\n",
      "-> 0.0000860, 0.0000859, L-S 1\n",
      "-> 0.0000859, 0.0000859, L-S 0\n",
      "-> 0.0000859, 0.0000858, L-S 2\n",
      "-> 0.0000858, 0.0000855, L-S 2\n",
      "loss= 8.55246398714371e-05\n",
      "iteration  11\n",
      "-> 0.0000855, 0.0000853, L-S 23\n",
      "-> 0.0000853, 0.0000850, L-S 0\n",
      "-> 0.0000850, 0.0000848, L-S 2\n",
      "-> 0.0000848, 0.0000848, L-S 1\n",
      "-> 0.0000848, 0.0000847, L-S 1\n",
      "-> 0.0000847, 0.0000845, L-S 2\n",
      "-> 0.0000845, 0.0000844, L-S 1\n",
      "-> 0.0000844, 0.0000843, L-S 2\n",
      "-> 0.0000843, 0.0000842, L-S 2\n",
      "-> 0.0000842, 0.0000842, L-S 1\n",
      "-> 0.0000842, 0.0000841, L-S 3\n",
      "loss= 8.409962902078405e-05\n",
      "iteration  12\n",
      "-> 0.0000841, 0.0000840, L-S 23\n",
      "-> 0.0000840, 0.0000840, L-S 3\n",
      "-> 0.0000840, 0.0000839, L-S 0\n",
      "-> 0.0000839, 0.0000839, L-S 1\n",
      "-> 0.0000839, 0.0000837, L-S 1\n",
      "-> 0.0000837, 0.0000837, L-S 0\n",
      "-> 0.0000837, 0.0000837, L-S 2\n",
      "-> 0.0000837, 0.0000836, L-S 2\n",
      "-> 0.0000836, 0.0000834, L-S 2\n",
      "-> 0.0000834, 0.0000834, L-S 2\n",
      "-> 0.0000834, 0.0000833, L-S 2\n",
      "loss= 8.331116987392306e-05\n",
      "iteration  13\n",
      "-> 0.0000833, 0.0000833, L-S 23\n",
      "-> 0.0000833, 0.0000833, L-S 3\n",
      "-> 0.0000833, 0.0000832, L-S 0\n",
      "-> 0.0000832, 0.0000832, L-S 2\n",
      "-> 0.0000832, 0.0000831, L-S 1\n",
      "-> 0.0000831, 0.0000831, L-S 1\n",
      "-> 0.0000831, 0.0000830, L-S 1\n",
      "-> 0.0000830, 0.0000830, L-S 1\n",
      "-> 0.0000830, 0.0000829, L-S 1\n",
      "-> 0.0000829, 0.0000829, L-S 1\n",
      "-> 0.0000829, 0.0000829, L-S 1\n",
      "loss= 8.285124931717291e-05\n",
      "iteration  14\n",
      "-> 0.0000829, 0.0000827, L-S 24\n",
      "-> 0.0000827, 0.0000827, L-S 0\n",
      "-> 0.0000827, 0.0000827, L-S 1\n",
      "-> 0.0000827, 0.0000827, L-S 2\n",
      "-> 0.0000827, 0.0000827, L-S 2\n",
      "-> 0.0000827, 0.0000826, L-S 2\n",
      "-> 0.0000826, 0.0000826, L-S 2\n",
      "-> 0.0000826, 0.0000826, L-S 1\n",
      "-> 0.0000826, 0.0000826, L-S 1\n",
      "-> 0.0000826, 0.0000826, L-S 0\n",
      "-> 0.0000826, 0.0000825, L-S 1\n",
      "loss= 8.25199531391263e-05\n",
      "iteration  15\n",
      "-> 0.0000825, 0.0000824, L-S 23\n",
      "-> 0.0000824, 0.0000824, L-S 0\n",
      "-> 0.0000824, 0.0000823, L-S 2\n",
      "-> 0.0000823, 0.0000823, L-S 2\n",
      "-> 0.0000823, 0.0000823, L-S 2\n",
      "-> 0.0000823, 0.0000822, L-S 3\n",
      "-> 0.0000822, 0.0000822, L-S 1\n",
      "-> 0.0000822, 0.0000822, L-S 2\n",
      "-> 0.0000822, 0.0000822, L-S 1\n",
      "-> 0.0000822, 0.0000822, L-S 1\n",
      "-> 0.0000822, 0.0000822, L-S 1\n",
      "loss= 8.217202412197366e-05\n",
      "iteration  16\n",
      "-> 0.0000822, 0.0000821, L-S 23\n",
      "-> 0.0000821, 0.0000821, L-S 0\n",
      "-> 0.0000821, 0.0000821, L-S 2\n",
      "-> 0.0000821, 0.0000821, L-S 2\n",
      "-> 0.0000821, 0.0000820, L-S 2\n",
      "-> 0.0000820, 0.0000820, L-S 2\n",
      "-> 0.0000820, 0.0000820, L-S 2\n",
      "-> 0.0000820, 0.0000820, L-S 2\n",
      "-> 0.0000820, 0.0000820, L-S 2\n",
      "-> 0.0000820, 0.0000820, L-S 2\n",
      "-> 0.0000820, 0.0000819, L-S 2\n",
      "loss= 8.19498163764365e-05\n",
      "iteration  17\n",
      "-> 0.0000819, 0.0000819, L-S 23\n",
      "-> 0.0000819, 0.0000819, L-S 1\n",
      "-> 0.0000819, 0.0000819, L-S 1\n",
      "-> 0.0000819, 0.0000818, L-S 2\n",
      "-> 0.0000818, 0.0000818, L-S 2\n",
      "-> 0.0000818, 0.0000818, L-S 2\n",
      "-> 0.0000818, 0.0000818, L-S 3\n",
      "-> 0.0000818, 0.0000818, L-S 1\n",
      "-> 0.0000818, 0.0000818, L-S 2\n",
      "-> 0.0000818, 0.0000818, L-S 1\n",
      "-> 0.0000818, 0.0000818, L-S 2\n",
      "loss= 8.178287680493668e-05\n",
      "iteration  18\n",
      "-> 0.0000818, 0.0000817, L-S 24\n",
      "-> 0.0000817, 0.0000817, L-S 0\n",
      "-> 0.0000817, 0.0000817, L-S 2\n",
      "-> 0.0000817, 0.0000817, L-S 2\n",
      "-> 0.0000817, 0.0000817, L-S 2\n",
      "-> 0.0000817, 0.0000817, L-S 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> 0.0000817, 0.0000817, L-S 2\n",
      "-> 0.0000817, 0.0000817, L-S 2\n",
      "-> 0.0000817, 0.0000817, L-S 2\n",
      "-> 0.0000817, 0.0000817, L-S 2\n",
      "-> 0.0000817, 0.0000817, L-S 2\n",
      "loss= 8.167414489435032e-05\n",
      "iteration  19\n",
      "-> 0.0000817, 0.0000817, L-S 24\n",
      "-> 0.0000817, 0.0000817, L-S 1\n",
      "-> 0.0000817, 0.0000816, L-S 1\n",
      "-> 0.0000816, 0.0000816, L-S 1\n",
      "-> 0.0000816, 0.0000816, L-S 1\n",
      "-> 0.0000816, 0.0000816, L-S 1\n",
      "-> 0.0000816, 0.0000816, L-S 1\n",
      "-> 0.0000816, 0.0000816, L-S 1\n",
      "-> 0.0000816, 0.0000816, L-S 1\n",
      "-> 0.0000816, 0.0000816, L-S 1\n",
      "-> 0.0000816, 0.0000816, L-S 1\n",
      "loss= 8.159155549947172e-05\n",
      "iteration  20\n",
      "-> 0.0000816, 0.0000816, L-S 25\n",
      "-> 0.0000816, 0.0000816, L-S 0\n",
      "-> 0.0000816, 0.0000816, L-S 1\n",
      "-> 0.0000816, 0.0000816, L-S 1\n",
      "-> 0.0000816, 0.0000816, L-S 2\n",
      "-> 0.0000816, 0.0000815, L-S 2\n",
      "-> 0.0000815, 0.0000815, L-S 2\n",
      "-> 0.0000815, 0.0000815, L-S 2\n",
      "-> 0.0000815, 0.0000815, L-S 2\n",
      "-> 0.0000815, 0.0000815, L-S 2\n",
      "-> 0.0000815, 0.0000815, L-S 2\n",
      "loss= 8.152631198754534e-05\n",
      "iteration  21\n",
      "-> 0.0000815, 0.0000815, L-S 25\n",
      "-> 0.0000815, 0.0000815, L-S 1\n",
      "-> 0.0000815, 0.0000815, L-S 1\n",
      "-> 0.0000815, 0.0000815, L-S 1\n",
      "-> 0.0000815, 0.0000815, L-S 1\n",
      "-> 0.0000815, 0.0000815, L-S 1\n",
      "-> 0.0000815, 0.0000815, L-S 1\n",
      "-> 0.0000815, 0.0000815, L-S 0\n",
      "-> 0.0000815, 0.0000815, L-S 1\n",
      "-> 0.0000815, 0.0000815, L-S 0\n",
      "-> 0.0000815, 0.0000815, L-S 1\n",
      "loss= 8.148666529450566e-05\n",
      "iteration  22\n",
      "-> 0.0000815, 0.0000815, L-S 24\n",
      "-> 0.0000815, 0.0000815, L-S 1\n",
      "-> 0.0000815, 0.0000815, L-S 1\n",
      "-> 0.0000815, 0.0000814, L-S 1\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "loss= 8.14183586044237e-05\n",
      "iteration  23\n",
      "-> 0.0000814, 0.0000814, L-S 25\n",
      "-> 0.0000814, 0.0000814, L-S 0\n",
      "-> 0.0000814, 0.0000814, L-S 1\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "loss= 8.138092380249873e-05\n",
      "iteration  24\n",
      "-> 0.0000814, 0.0000814, L-S 25\n",
      "-> 0.0000814, 0.0000814, L-S 2\n",
      "-> 0.0000814, 0.0000814, L-S 1\n",
      "-> 0.0000814, 0.0000814, L-S 1\n",
      "-> 0.0000814, 0.0000814, L-S 1\n",
      "-> 0.0000814, 0.0000814, L-S 1\n",
      "-> 0.0000814, 0.0000814, L-S 1\n",
      "-> 0.0000814, 0.0000814, L-S 1\n",
      "-> 0.0000814, 0.0000814, L-S 1\n",
      "-> 0.0000814, 0.0000814, L-S 1\n",
      "-> 0.0000814, 0.0000814, L-S 1\n",
      "loss= 8.135677489917725e-05\n",
      "iteration  25\n",
      "-> 0.0000814, 0.0000814, L-S 26\n",
      "-> 0.0000814, 0.0000814, L-S 0\n",
      "-> 0.0000814, 0.0000814, L-S 0\n",
      "-> 0.0000814, 0.0000814, L-S 6\n",
      "-> 0.0000814, 0.0000813, L-S 1\n",
      "-> 0.0000813, 0.0000813, L-S 0\n",
      "-> 0.0000813, 0.0000813, L-S 0\n",
      "-> 0.0000813, 0.0000813, L-S 1\n",
      "-> 0.0000813, 0.0000813, L-S 1\n",
      "-> 0.0000813, 0.0000813, L-S 1\n",
      "-> 0.0000813, 0.0000813, L-S 1\n",
      "loss= 8.127604814944789e-05\n",
      "iteration  26\n",
      "-> 0.0000813, 0.0000813, L-S 24\n",
      "-> 0.0000813, 0.0000813, L-S 1\n",
      "-> 0.0000813, 0.0000812, L-S 1\n",
      "-> 0.0000812, 0.0000812, L-S 1\n",
      "-> 0.0000812, 0.0000812, L-S 1\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "loss= 8.118696860037744e-05\n",
      "iteration  27\n",
      "-> 0.0000812, 0.0000812, L-S 25\n",
      "-> 0.0000812, 0.0000812, L-S 0\n",
      "-> 0.0000812, 0.0000812, L-S 1\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "-> 0.0000812, 0.0000812, L-S 2\n",
      "-> 0.0000812, 0.0000812, L-S 3\n",
      "-> 0.0000812, 0.0000812, L-S 1\n",
      "loss= 8.115579839795828e-05\n",
      "iteration  28\n",
      "-> 0.0000812, 0.0000811, L-S 26\n",
      "-> 0.0000811, 0.0000811, L-S 0\n",
      "-> 0.0000811, 0.0000811, L-S 0\n",
      "-> 0.0000811, 0.0000811, L-S 3\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 0\n",
      "-> 0.0000811, 0.0000811, L-S 3\n",
      "loss= 8.114217052934691e-05\n",
      "iteration  29\n",
      "-> 0.0000811, 0.0000811, L-S 26\n",
      "-> 0.0000811, 0.0000811, L-S 0\n",
      "-> 0.0000811, 0.0000811, L-S 0\n",
      "-> 0.0000811, 0.0000811, L-S 2\n",
      "-> 0.0000811, 0.0000811, L-S 2\n",
      "-> 0.0000811, 0.0000811, L-S 3\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "loss= 8.113271906040609e-05\n",
      "iteration  30\n",
      "-> 0.0000811, 0.0000811, L-S 25\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "loss= 8.112033538054675e-05\n",
      "iteration  31\n",
      "-> 0.0000811, 0.0000811, L-S 26\n",
      "-> 0.0000811, 0.0000811, L-S 0\n",
      "-> 0.0000811, 0.0000811, L-S 0\n",
      "-> 0.0000811, 0.0000811, L-S 4\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 3\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "-> 0.0000811, 0.0000811, L-S 0\n",
      "-> 0.0000811, 0.0000811, L-S 2\n",
      "-> 0.0000811, 0.0000811, L-S 2\n",
      "-> 0.0000811, 0.0000811, L-S 1\n",
      "loss= 8.111433271551505e-05\n",
      "/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#recon from simulated file\n",
    "!python sim_and_recon.py -r -f BC33_sim21spokes_origsmap_None_1.33e-06.mat -i 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.1G\r\n",
      "-rw-rw---- 1 zh1115 knolllab  32K Jul 15 16:04 test.ipynb\r\n",
      "-rw-rw---- 1 zh1115 knolllab 8.0M Jul 15 16:02 targetrecombine_caseBC33_csNone_Recon_iGRASP.gif\r\n",
      "-rw-rw---- 1 zh1115 knolllab  12M Jul 15 16:02 target_caseBC33_csNone_Recon_iGRASP.gif\r\n",
      "-rw-rw---- 1 zh1115 knolllab 194M Jul 15 16:02 BC33_sim21spokes_origsmap_None_1.33e-06.mat\r\n",
      "drwxrws--- 2 zh1115 knolllab 4.0K Jul 15 16:02 __pycache__\r\n",
      "-rw-rw---- 1 zh1115 knolllab  41K Jul 15 16:01 simulation_and_reconstruction.py\r\n",
      "-rw-rw---- 1 zh1115 knolllab  11M Jul 15 15:33 iGRASP_BC33_sim20210128.gif\r\n",
      "-rw-rw---- 1 zh1115 knolllab  26M Jul 15 15:33 BC33_sim20210128.pt\r\n",
      "-rw-rw---- 1 zh1115 knolllab  18M Jul 15 15:12 BC33_sim20210128_adjnufft.pt\r\n",
      "-rw-rw---- 1 zh1115 knolllab  48K Jul 15 11:44 simulation_and_reconstruction_allfunctions.py\r\n",
      "drwxrws--- 3 zh1115 knolllab 4.0K Jul 15 11:38 utils\r\n",
      "-rw-rw---- 1 zh1115 knolllab  11M Jul  9 23:03 iGRASP_BC33_sim20210128_niter3.gif\r\n",
      "-rw-rw---- 1 zh1115 knolllab  26M Jul  9 23:03 BC33_sim20210128_niter3.pt\r\n",
      "-rw-rw---- 1 zh1115 knolllab 5.0K Jul  9 22:57 iGRASP_recon.py\r\n",
      "-rw-rw---- 1 zh1115 knolllab  11M Jul  9 22:47 iGRASP_BC33_sim20210128_niter32.gif\r\n",
      "-rw-rw---- 1 zh1115 knolllab  26M Jul  9 22:47 BC33_sim20210128._niter32.pt\r\n",
      "-rw-rw---- 1 zh1115 knolllab 5.0K Jul  9 21:16 iGRASP_recon_noisefree_originalsmap.py\r\n",
      "-rw-rw---- 1 zh1115 knolllab  22K Jul  9 21:05 sim_and_recon.py\r\n",
      "-rw-rw---- 1 zh1115 knolllab 8.4M Jul  9 18:09 sim_21spokes_loadedsmap_caseBC29_csNone_Recon__lambda1.2434238669811748e-06_tolerance1e-12_iterations32_noise1.33e-06_nodcomp.gif\r\n",
      "-rw-rw---- 1 zh1115 knolllab 758M Jul  9 18:09 sim_21spokes_loadedsmap_caseBC29_csNone_Result__lambda1.2434238669811748e-06_tolerance1e-12_iterations32_noise1.33e-06_loadedsmap_nodcomp.mat\r\n",
      "drwxrws--- 2 zh1115 knolllab 4.0K Jul  9 17:04 kspace\r\n",
      "-rw-rw---- 1 zh1115 knolllab  367 Jul  9 16:46 sim.sh\r\n",
      "-rw-rw---- 1 zh1115 knolllab  48K Jul  9 16:39 simulation_and_reconstruction_beta.py\r\n",
      "-rw-rw---- 1 zh1115 knolllab    5 Jul  9 15:52 sim_BC33.txt\r\n",
      "-rw-rw---- 1 zh1115 knolllab  305 Jul  9 15:51 sim_list.txt\r\n",
      "-rw-rw---- 1 zh1115 knolllab  578 Jul  9 14:21 sim_loop_20210301_spk55.sh\r\n",
      "-rw-rw---- 1 zh1115 knolllab 1.4K Jul  9 14:21 recon_loop.sh\r\n",
      "-rw-rw---- 1 zh1115 knolllab  141 Jul  9 14:21 bsub_sim.sh\r\n",
      "-rw-rw---- 1 zh1115 knolllab  627 Jul  9 14:21 bsub_recon.sh\r\n",
      "-rw-rw---- 1 zh1115 knolllab 3.8K Jul  8 17:13 S0_and_smap.py\r\n",
      "-rw-rw---- 1 zh1115 knolllab  17K Jul  8 17:13 recon_fromoriginalkspace.py\r\n",
      "-rw-rw---- 1 zh1115 knolllab  14K Jul  8 17:13 Radial_simulation_origsmap.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -hlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!python iGRASP_recon.py --input BC33_sim21spokes_origsmap_None_1.33e-06.mat --output BC33_sim20210128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/dask/config.py:161: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "(640,)\n",
      "torch.Size([1, 16, 2, 320, 320])\n",
      "torch.Size([1, 16, 2, 320, 320])\n",
      "iteration  0\n",
      "-> 0.0015076, 0.0012383, L-S 25\n",
      "-> 0.0012383, 0.0007920, L-S 0\n",
      "-> 0.0007920, 0.0006738, L-S 1\n",
      "-> 0.0006738, 0.0006651, L-S 3\n",
      "-> 0.0006651, 0.0005745, L-S 0\n",
      "-> 0.0005745, 0.0005696, L-S 1\n",
      "-> 0.0005696, 0.0004208, L-S 0\n",
      "-> 0.0004208, 0.0003638, L-S 1\n",
      "-> 0.0003638, 0.0003467, L-S 4\n",
      "-> 0.0003467, 0.0003247, L-S 2\n",
      "-> 0.0003247, 0.0003176, L-S 1\n",
      "loss= 0.0003175546007696539\n",
      "iteration  1\n",
      "-> 0.0003176, 0.0002417, L-S 25\n",
      "-> 0.0002417, 0.0001382, L-S 0\n",
      "-> 0.0001382, 0.0001283, L-S 1\n",
      "-> 0.0001283, 0.0001281, L-S 5\n",
      "-> 0.0001281, 0.0001227, L-S 0\n",
      "-> 0.0001227, 0.0001212, L-S 2\n",
      "-> 0.0001212, 0.0001157, L-S 1\n",
      "-> 0.0001157, 0.0001121, L-S 2\n",
      "-> 0.0001121, 0.0001015, L-S 2\n",
      "-> 0.0001015, 0.0001000, L-S 0\n",
      "-> 0.0001000, 0.0000965, L-S 4\n",
      "loss= 9.651276923250407e-05\n",
      "iteration  2\n",
      "-> 0.0000965, 0.0000914, L-S 24\n",
      "-> 0.0000914, 0.0000880, L-S 2\n",
      "-> 0.0000880, 0.0000834, L-S 2\n",
      "-> 0.0000834, 0.0000821, L-S 0\n",
      "-> 0.0000821, 0.0000787, L-S 3\n",
      "-> 0.0000787, 0.0000712, L-S 0\n",
      "-> 0.0000712, 0.0000701, L-S 2\n",
      "-> 0.0000701, 0.0000700, L-S 2\n",
      "-> 0.0000700, 0.0000679, L-S 1\n",
      "-> 0.0000679, 0.0000662, L-S 2\n",
      "-> 0.0000662, 0.0000646, L-S 1\n",
      "loss= 6.461427255999297e-05\n",
      "/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "!python iGRASP_recon.py --input BC33_sim21spokes_origsmap_None_1.33e-06.mat --output BC33_sim20210128 -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/dask/config.py:161: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "torch.Size([1, 16, 2, 320, 320])\n",
      "torch.Size([1, 16, 2, 320, 320])\n",
      "iteration  0\n",
      "-> 0.0015074, 0.0012376, L-S 25\n",
      "-> 0.0012376, 0.0007906, L-S 0\n",
      "-> 0.0007906, 0.0006720, L-S 1\n",
      "-> 0.0006720, 0.0006628, L-S 3\n",
      "-> 0.0006628, 0.0005717, L-S 0\n",
      "-> 0.0005717, 0.0005671, L-S 1\n",
      "-> 0.0005671, 0.0004189, L-S 0\n",
      "-> 0.0004189, 0.0003624, L-S 1\n",
      "-> 0.0003624, 0.0003456, L-S 4\n",
      "-> 0.0003456, 0.0003238, L-S 2\n",
      "-> 0.0003238, 0.0003167, L-S 1\n",
      "loss= 0.000316686142468825\n",
      "iteration  1\n",
      "-> 0.0003167, 0.0002406, L-S 25\n",
      "-> 0.0002406, 0.0001366, L-S 0\n",
      "-> 0.0001366, 0.0001266, L-S 1\n",
      "-> 0.0001266, 0.0001264, L-S 5\n",
      "-> 0.0001264, 0.0001209, L-S 0\n",
      "-> 0.0001209, 0.0001195, L-S 2\n",
      "-> 0.0001195, 0.0001142, L-S 1\n",
      "-> 0.0001142, 0.0001109, L-S 2\n",
      "-> 0.0001109, 0.0001003, L-S 2\n",
      "-> 0.0001003, 0.0000990, L-S 0\n",
      "-> 0.0000990, 0.0000955, L-S 4\n",
      "loss= 9.553251584293321e-05\n",
      "iteration  2\n",
      "-> 0.0000955, 0.0000908, L-S 24\n",
      "-> 0.0000908, 0.0000884, L-S 2\n",
      "-> 0.0000884, 0.0000839, L-S 2\n",
      "-> 0.0000839, 0.0000833, L-S 0\n",
      "-> 0.0000833, 0.0000797, L-S 3\n",
      "-> 0.0000797, 0.0000718, L-S 0\n",
      "-> 0.0000718, 0.0000704, L-S 2\n",
      "-> 0.0000704, 0.0000696, L-S 2\n",
      "-> 0.0000696, 0.0000687, L-S 0\n",
      "-> 0.0000687, 0.0000686, L-S 6\n",
      "-> 0.0000686, 0.0000674, L-S 3\n",
      "loss= 6.737723742844537e-05\n",
      "/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "!python iGRASP_recon.py --input BC33_sim21spokes_origsmap_None_1.33e-06.mat --output BC33_sim20210128 -n 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/dask/config.py:161: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "torch.Size([1, 16, 2, 320, 320])\n",
      "torch.Size([1, 16, 2, 320, 320])\n",
      "iteration  0\n",
      "-> 0.0015074, 0.0012376, L-S 25\n",
      "-> 0.0012376, 0.0007906, L-S 0\n",
      "-> 0.0007906, 0.0006720, L-S 1\n",
      "-> 0.0006720, 0.0006628, L-S 3\n",
      "-> 0.0006628, 0.0005717, L-S 0\n",
      "-> 0.0005717, 0.0005671, L-S 1\n",
      "-> 0.0005671, 0.0004189, L-S 0\n",
      "-> 0.0004189, 0.0003624, L-S 1\n",
      "-> 0.0003624, 0.0003456, L-S 4\n",
      "-> 0.0003456, 0.0003238, L-S 2\n",
      "-> 0.0003238, 0.0003167, L-S 1\n",
      "loss= 0.00031668582232668996\n",
      "iteration  1\n",
      "-> 0.0003167, 0.0002406, L-S 25\n",
      "-> 0.0002406, 0.0001366, L-S 0\n",
      "-> 0.0001366, 0.0001266, L-S 1\n",
      "-> 0.0001266, 0.0001264, L-S 5\n",
      "-> 0.0001264, 0.0001209, L-S 0\n",
      "-> 0.0001209, 0.0001195, L-S 2\n",
      "-> 0.0001195, 0.0001142, L-S 1\n",
      "-> 0.0001142, 0.0001109, L-S 2\n",
      "-> 0.0001109, 0.0001003, L-S 2\n",
      "-> 0.0001003, 0.0000990, L-S 0\n",
      "-> 0.0000990, 0.0000955, L-S 4\n",
      "loss= 9.553247946314514e-05\n",
      "iteration  2\n",
      "-> 0.0000955, 0.0000908, L-S 24\n",
      "-> 0.0000908, 0.0000884, L-S 2\n",
      "-> 0.0000884, 0.0000839, L-S 2\n",
      "-> 0.0000839, 0.0000833, L-S 0\n",
      "-> 0.0000833, 0.0000797, L-S 3\n",
      "-> 0.0000797, 0.0000718, L-S 0\n",
      "-> 0.0000718, 0.0000704, L-S 2\n",
      "-> 0.0000704, 0.0000696, L-S 2\n",
      "-> 0.0000696, 0.0000687, L-S 0\n",
      "-> 0.0000687, 0.0000686, L-S 6\n",
      "-> 0.0000686, 0.0000674, L-S 3\n",
      "loss= 6.73772519803606e-05\n",
      "iteration  3\n",
      "-> 0.0000674, 0.0000638, L-S 25\n",
      "-> 0.0000638, 0.0000620, L-S 0\n",
      "-> 0.0000620, 0.0000618, L-S 0\n",
      "-> 0.0000618, 0.0000616, L-S 4\n",
      "-> 0.0000616, 0.0000608, L-S 3\n",
      "-> 0.0000608, 0.0000605, L-S 0\n",
      "-> 0.0000605, 0.0000603, L-S 3\n",
      "-> 0.0000603, 0.0000602, L-S 1\n",
      "-> 0.0000602, 0.0000602, L-S 2\n",
      "-> 0.0000602, 0.0000585, L-S 0\n",
      "-> 0.0000585, 0.0000583, L-S 1\n",
      "loss= 5.8283556427340955e-05\n",
      "iteration  4\n",
      "-> 0.0000583, 0.0000581, L-S 25\n",
      "-> 0.0000581, 0.0000579, L-S 0\n",
      "-> 0.0000579, 0.0000577, L-S 2\n",
      "-> 0.0000577, 0.0000574, L-S 0\n",
      "-> 0.0000574, 0.0000573, L-S 1\n",
      "-> 0.0000573, 0.0000573, L-S 3\n",
      "-> 0.0000573, 0.0000568, L-S 1\n",
      "-> 0.0000568, 0.0000563, L-S 0\n",
      "-> 0.0000563, 0.0000555, L-S 1\n",
      "-> 0.0000555, 0.0000554, L-S 1\n",
      "-> 0.0000554, 0.0000550, L-S 1\n",
      "loss= 5.503476859303191e-05\n",
      "iteration  5\n",
      "-> 0.0000550, 0.0000542, L-S 23\n",
      "-> 0.0000542, 0.0000539, L-S 3\n",
      "-> 0.0000539, 0.0000538, L-S 0\n",
      "-> 0.0000538, 0.0000536, L-S 2\n",
      "-> 0.0000536, 0.0000535, L-S 2\n",
      "-> 0.0000535, 0.0000535, L-S 4\n",
      "-> 0.0000535, 0.0000534, L-S 2\n",
      "-> 0.0000534, 0.0000534, L-S 0\n",
      "-> 0.0000534, 0.0000532, L-S 2\n",
      "-> 0.0000532, 0.0000531, L-S 2\n",
      "-> 0.0000531, 0.0000531, L-S 0\n",
      "loss= 5.305797094479203e-05\n",
      "iteration  6\n",
      "-> 0.0000531, 0.0000530, L-S 25\n",
      "-> 0.0000530, 0.0000530, L-S 2\n",
      "-> 0.0000530, 0.0000526, L-S 1\n",
      "-> 0.0000526, 0.0000525, L-S 0\n",
      "-> 0.0000525, 0.0000524, L-S 0\n",
      "-> 0.0000524, 0.0000524, L-S 4\n",
      "-> 0.0000524, 0.0000524, L-S 1\n",
      "-> 0.0000524, 0.0000524, L-S 2\n",
      "-> 0.0000524, 0.0000524, L-S 1\n",
      "-> 0.0000524, 0.0000523, L-S 1\n",
      "-> 0.0000523, 0.0000523, L-S 0\n",
      "loss= 5.227784640737809e-05\n",
      "iteration  7\n",
      "-> 0.0000523, 0.0000522, L-S 25\n",
      "-> 0.0000522, 0.0000521, L-S 0\n",
      "-> 0.0000521, 0.0000520, L-S 1\n",
      "-> 0.0000520, 0.0000520, L-S 0\n",
      "-> 0.0000520, 0.0000519, L-S 3\n",
      "-> 0.0000519, 0.0000519, L-S 2\n",
      "-> 0.0000519, 0.0000519, L-S 2\n",
      "-> 0.0000519, 0.0000518, L-S 1\n",
      "-> 0.0000518, 0.0000518, L-S 0\n",
      "-> 0.0000518, 0.0000517, L-S 0\n",
      "-> 0.0000517, 0.0000517, L-S 3\n",
      "loss= 5.16847321705427e-05\n",
      "iteration  8\n",
      "-> 0.0000517, 0.0000516, L-S 24\n",
      "-> 0.0000516, 0.0000516, L-S 3\n",
      "-> 0.0000516, 0.0000515, L-S 1\n",
      "-> 0.0000515, 0.0000514, L-S 0\n",
      "-> 0.0000514, 0.0000514, L-S 2\n",
      "-> 0.0000514, 0.0000513, L-S 1\n",
      "-> 0.0000513, 0.0000512, L-S 2\n",
      "-> 0.0000512, 0.0000512, L-S 1\n",
      "-> 0.0000512, 0.0000512, L-S 3\n",
      "-> 0.0000512, 0.0000512, L-S 1\n",
      "-> 0.0000512, 0.0000512, L-S 1\n",
      "loss= 5.119977140566334e-05\n",
      "iteration  9\n",
      "-> 0.0000512, 0.0000511, L-S 25\n",
      "-> 0.0000511, 0.0000511, L-S 0\n",
      "-> 0.0000511, 0.0000511, L-S 1\n",
      "-> 0.0000511, 0.0000510, L-S 2\n",
      "-> 0.0000510, 0.0000510, L-S 2\n",
      "-> 0.0000510, 0.0000510, L-S 1\n",
      "-> 0.0000510, 0.0000510, L-S 2\n",
      "-> 0.0000510, 0.0000509, L-S 1\n",
      "-> 0.0000509, 0.0000509, L-S 2\n",
      "-> 0.0000509, 0.0000509, L-S 2\n",
      "-> 0.0000509, 0.0000509, L-S 1\n",
      "loss= 5.0882052164524794e-05\n",
      "iteration  10\n",
      "-> 0.0000509, 0.0000509, L-S 25\n",
      "-> 0.0000509, 0.0000509, L-S 1\n",
      "-> 0.0000509, 0.0000508, L-S 1\n",
      "-> 0.0000508, 0.0000508, L-S 0\n",
      "-> 0.0000508, 0.0000508, L-S 0\n",
      "-> 0.0000508, 0.0000508, L-S 3\n",
      "-> 0.0000508, 0.0000508, L-S 1\n",
      "-> 0.0000508, 0.0000508, L-S 1\n",
      "-> 0.0000508, 0.0000507, L-S 1\n",
      "-> 0.0000507, 0.0000507, L-S 0\n",
      "-> 0.0000507, 0.0000506, L-S 2\n",
      "loss= 5.0586473662406206e-05\n",
      "iteration  11\n",
      "-> 0.0000506, 0.0000506, L-S 25\n",
      "-> 0.0000506, 0.0000505, L-S 0\n",
      "-> 0.0000505, 0.0000504, L-S 2\n",
      "-> 0.0000504, 0.0000504, L-S 0\n",
      "-> 0.0000504, 0.0000504, L-S 1\n",
      "-> 0.0000504, 0.0000504, L-S 2\n",
      "-> 0.0000504, 0.0000504, L-S 0\n",
      "-> 0.0000504, 0.0000504, L-S 2\n",
      "-> 0.0000504, 0.0000504, L-S 3\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"iGRASP_recon.py\", line 148, in <module>\n",
      "    main()\n",
      "  File \"iGRASP_recon.py\", line 139, in main\n",
      "    niter = niteration)\n",
      "  File \"/gpfs/data/knolllab/knolllabspace/hzn/storage/push_to_git/radialmri/radialmri/simulation_and_reconstruction.py\", line 1022, in RadialRecon\n",
      "    loss = optimizer.step(criterion);\n",
      "  File \"/gpfs/data/knolllab/knolllabspace/hzn/storage/push_to_git/radialmri/radialmri/utils/cg.py\", line 94, in step\n",
      "    loss = closure(requires_grad=False)\n",
      "  File \"/gpfs/data/knolllab/knolllabspace/hzn/storage/push_to_git/radialmri/radialmri/simulation_and_reconstruction.py\", line 997, in criterion\n",
      "    output = model.forward(x0, traj, coil_sensitivities, w)\n",
      "  File \"/gpfs/data/knolllab/knolllabspace/hzn/storage/push_to_git/radialmri/radialmri/simulation_and_reconstruction.py\", line 583, in forward\n",
      "    y = self.nufft_op(cimage, k)\n",
      "  File \"/gpfs/share/apps/anaconda3/gpu/5.2.0/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/gpfs/home/zh1115/.local/lib/python3.6/site-packages/torchkbnufft/kbnufft.py\", line 162, in forward\n",
      "    y = KbNufftFunction.apply(x, om, interpob, interp_mats)\n",
      "  File \"/gpfs/home/zh1115/.local/lib/python3.6/site-packages/torchkbnufft/functional/kbnufft.py\", line 27, in forward\n",
      "    y = KbInterpFunction.apply(x, om, interpob, interp_mats)\n",
      "  File \"/gpfs/home/zh1115/.local/lib/python3.6/site-packages/torchkbnufft/functional/kbinterp.py\", line 13, in forward\n",
      "    y = kbinterp(x, om, interpob, interp_mats)\n",
      "  File \"/gpfs/home/zh1115/.local/lib/python3.6/site-packages/torchkbnufft/nufft/interp_functions.py\", line 311, in kbinterp\n",
      "    device=device\n",
      "  File \"/gpfs/home/zh1115/.local/lib/python3.6/site-packages/torchkbnufft/nufft/interp_functions.py\", line 139, in run_interp\n",
      "    table[d][:, curdistind[d, :] + centers[d]],\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python iGRASP_recon.py --input BC33_sim21spokes_origsmap_None_1.33e-06.mat --output BC33_sim20210128 -n 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 15 13:59:11 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.42.01    Driver Version: 470.42.01    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\r\n",
      "| N/A   35C    P0    53W / 300W |      0MiB / 16160MiB |      1%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
